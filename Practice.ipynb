{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60457d49-00f6-4687-bc50-9c828ed649c5",
   "metadata": {},
   "source": [
    "1. Distributed Processing: Breaks down large data tasks across a cluster.\n",
    "2. Lazy Evaluation: Optimizes execution plans.\n",
    "3. In-Memory Computation: Reduces I/O operations.\n",
    "4. DataFrame API: Simplifies data manipulation and optimizes performance.\n",
    "5. Fault Tolerance: Ensures resilience against node failures.\n",
    "6. Efficient Joins: Minimizes data shuffling.\n",
    "7. Resource Management: Allocates appropriate resources for tasks.\n",
    "8. Configurable Memory Management: Fine-tunes performance parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "524e4987-57eb-48d2-bccf-f84bb3e6e825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/23 18:28:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Spark Session\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185cf767-012a-48c6-999a-e4526bad50eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://vinayaks-mbp.station:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Session</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10ef633d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b6bb9-9e9b-45ee-9b8c-d218e03dfa14",
   "metadata": {},
   "source": [
    "##### Tips:\n",
    "\n",
    "1. Spark Prefers Lazy Evaluation Spark will not do the transformation until we call an action. we can call n number of transformations but it will not get executed until the action get called.\n",
    "\n",
    "2. Spark UI is application UI, It helps us understand what is happening with the data in background with the jobs.\n",
    "\n",
    "3. we can also use spark interactive shell to work with spark(on mac, you can use spark-shell command in terminal to use spark shell.)\n",
    "\n",
    "Interview Question:\n",
    "\n",
    "Since  spark session you can assign a different spark sessions.(vinayak = spark.getActiveSession() and after this spark gives memory location where spark session is on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9448dcab-7d3c-4b86-8286-778abedc8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emp Data & Schema\n",
    "\n",
    "emp_data = [\n",
    "    [\"001\",\"101\",\"John Doe\",\"30\",\"Male\",\"50000\",\"2015-01-01\"],\n",
    "    [\"002\",\"101\",\"Jane Smith\",\"25\",\"Female\",\"45000\",\"2016-02-15\"],\n",
    "    [\"003\",\"102\",\"Bob Brown\",\"35\",\"Male\",\"55000\",\"2014-05-01\"],\n",
    "    [\"004\",\"102\",\"Alice Lee\",\"28\",\"Female\",\"48000\",\"2017-09-30\"],\n",
    "    [\"005\",\"103\",\"Jack Chan\",\"40\",\"Male\",\"60000\",\"2013-04-01\"],\n",
    "    [\"006\",\"103\",\"Jill Wong\",\"32\",\"Female\",\"52000\",\"2018-07-01\"],\n",
    "    [\"007\",\"101\",\"James Johnson\",\"42\",\"Male\",\"70000\",\"2012-03-15\"],\n",
    "    [\"008\",\"102\",\"Kate Kim\",\"29\",\"Female\",\"51000\",\"2019-10-01\"],\n",
    "    [\"009\",\"103\",\"Tom Tan\",\"33\",\"Male\",\"58000\",\"2016-06-01\"],\n",
    "    [\"010\",\"104\",\"Lisa Lee\",\"27\",\"Female\",\"47000\",\"2018-08-01\"],\n",
    "    [\"011\",\"104\",\"David Park\",\"38\",\"Male\",\"65000\",\"2015-11-01\"],\n",
    "    [\"012\",\"105\",\"Susan Chen\",\"31\",\"Female\",\"54000\",\"2017-02-15\"],\n",
    "    [\"013\",\"106\",\"Brian Kim\",\"45\",\"Male\",\"75000\",\"2011-07-01\"],\n",
    "    [\"014\",\"107\",\"Emily Lee\",\"26\",\"Female\",\"46000\",\"2019-01-01\"],\n",
    "    [\"015\",\"106\",\"Michael Lee\",\"37\",\"Male\",\"63000\",\"2014-09-30\"],\n",
    "    [\"016\",\"107\",\"Kelly Zhang\",\"30\",\"Female\",\"49000\",\"2018-04-01\"],\n",
    "    [\"017\",\"105\",\"George Wang\",\"34\",\"Male\",\"57000\",\"2016-03-15\"],\n",
    "    [\"018\",\"104\",\"Nancy Liu\",\"29\",\"Female\",\"50000\",\"2017-06-01\"],\n",
    "    [\"019\",\"103\",\"Steven Chen\",\"36\",\"Male\",\"62000\",\"2015-08-01\"],\n",
    "    [\"020\",\"102\",\"Grace Kim\",\"32\",\"Female\",\"53000\",\"2018-11-01\"]\n",
    "]\n",
    "\n",
    "emp_schema = \"employee_id string, department_id string, name string, age string, gender string, salary string, hire_date string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5253199-a599-451a-a17d-2e110fd0ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very Important: You always need a datafram to manipulate columns\n",
    "# Create emp DataFrame\n",
    "\n",
    "emp = spark.createDataFrame(data=emp_data, schema=emp_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8684ea47-d83c-44d8-a186-cd983acdfd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n",
      "|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show emp dataframe (ACTION)\n",
    "\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa17971-199f-42dc-9a59-714e2727bdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('employee_id', StringType(), True), StructField('department_id', StringType(), True), StructField('name', StringType(), True), StructField('age', StringType(), True), StructField('gender', StringType(), True), StructField('salary', StringType(), True), StructField('hire_date', StringType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema for emp\n",
    "\n",
    "emp.schema\n",
    "\n",
    "# Spark Stores the schema basicaly in StructType along with each coloumn as StructField(\"Coloumn Name, DataType, and Nullable Field\"). \n",
    "# Nullable Field Explaination: In the StructType definition for a PySpark DataFrame schema, the True and False values are used to specify whether each field is nullable or not.\n",
    "# you can edit this to specify The True after StringType() in each StructField indicates that the corresponding field is nullable, meaning it can have null values.\n",
    "# If you set this value to False, it means that the field is not nullable and cannot contain null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db21a35b-15f3-4fb8-87ab-49b12e359f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small Example for Schema\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "schema_string = \"name string, age int\"\n",
    "\n",
    "schema_spark =  StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])\n",
    "# This is a spark Schema you can use above schema example, if you don't want to use this spark schema you can give spark_string to pyspark and then spark will convert it into \n",
    "# it's spark schema automatically. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d9bc2d7-83a1-40ae-a6ab-5aa40fae3cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'salary'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns and expression\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "\n",
    "# You can use col('salary')/ expr('salary') we will get the same result. because, any manipulation done on column is considered as a expression to call a column from dataframe\n",
    "# we can use emp[\"salary\"]\n",
    "emp[\"salary\"]\n",
    "emp.salary\n",
    "# expr['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42bd2208-4545-4ca1-b100-2e8cf1b51a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT columns\n",
    "# select employee_id, name, age, salary from emp\n",
    "\n",
    "emp_filtered = emp.select(col(\"employee_id\"), expr(\"name\"), emp.age, emp.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd50fef-6e96-4eed-b49a-39975f782444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+------+\n",
      "|employee_id|         name|age|salary|\n",
      "+-----------+-------------+---+------+\n",
      "|        001|     John Doe| 30| 50000|\n",
      "|        002|   Jane Smith| 25| 45000|\n",
      "|        003|    Bob Brown| 35| 55000|\n",
      "|        004|    Alice Lee| 28| 48000|\n",
      "|        005|    Jack Chan| 40| 60000|\n",
      "|        006|    Jill Wong| 32| 52000|\n",
      "|        007|James Johnson| 42| 70000|\n",
      "|        008|     Kate Kim| 29| 51000|\n",
      "|        009|      Tom Tan| 33| 58000|\n",
      "|        010|     Lisa Lee| 27| 47000|\n",
      "|        011|   David Park| 38| 65000|\n",
      "|        012|   Susan Chen| 31| 54000|\n",
      "|        013|    Brian Kim| 45| 75000|\n",
      "|        014|    Emily Lee| 26| 46000|\n",
      "|        015|  Michael Lee| 37| 63000|\n",
      "|        016|  Kelly Zhang| 30| 49000|\n",
      "|        017|  George Wang| 34| 57000|\n",
      "|        018|    Nancy Liu| 29| 50000|\n",
      "|        019|  Steven Chen| 36| 62000|\n",
      "|        020|    Grace Kim| 32| 53000|\n",
      "+-----------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHOW Dataframe (ACTION)\n",
    "\n",
    "emp_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1fddd5-1a4e-47d3-a98c-08bb9e6a166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using expr for select\n",
    "# select employee_id as emp_id, name, cast(age as int) as age, salary from emp_filtered\n",
    "\n",
    "emp_casted = emp_filtered.select(expr(\"employee_id as emp_id\"), emp.name, expr(\"cast(age as int) as age\"), emp.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419f9850-2ef3-43b5-82e2-5af228f3c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|   001|     John Doe| 30| 50000|\n",
      "|   002|   Jane Smith| 25| 45000|\n",
      "|   003|    Bob Brown| 35| 55000|\n",
      "|   004|    Alice Lee| 28| 48000|\n",
      "|   005|    Jack Chan| 40| 60000|\n",
      "|   006|    Jill Wong| 32| 52000|\n",
      "|   007|James Johnson| 42| 70000|\n",
      "|   008|     Kate Kim| 29| 51000|\n",
      "|   009|      Tom Tan| 33| 58000|\n",
      "|   010|     Lisa Lee| 27| 47000|\n",
      "|   011|   David Park| 38| 65000|\n",
      "|   012|   Susan Chen| 31| 54000|\n",
      "|   013|    Brian Kim| 45| 75000|\n",
      "|   014|    Emily Lee| 26| 46000|\n",
      "|   015|  Michael Lee| 37| 63000|\n",
      "|   016|  Kelly Zhang| 30| 49000|\n",
      "|   017|  George Wang| 34| 57000|\n",
      "|   018|    Nancy Liu| 29| 50000|\n",
      "|   019|  Steven Chen| 36| 62000|\n",
      "|   020|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHOW Dataframe (ACTION)\n",
    "\n",
    "emp_casted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "630452d5-5280-4f2f-be9c-725aca9018a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_casted_1 = emp_filtered.selectExpr(\"employee_id as emp_id\", \"name\", \"cast(age as int) as age\", \"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d7813ba-6810-4047-9527-6f849bcdb3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|   001|     John Doe| 30| 50000|\n",
      "|   002|   Jane Smith| 25| 45000|\n",
      "|   003|    Bob Brown| 35| 55000|\n",
      "|   004|    Alice Lee| 28| 48000|\n",
      "|   005|    Jack Chan| 40| 60000|\n",
      "|   006|    Jill Wong| 32| 52000|\n",
      "|   007|James Johnson| 42| 70000|\n",
      "|   008|     Kate Kim| 29| 51000|\n",
      "|   009|      Tom Tan| 33| 58000|\n",
      "|   010|     Lisa Lee| 27| 47000|\n",
      "|   011|   David Park| 38| 65000|\n",
      "|   012|   Susan Chen| 31| 54000|\n",
      "|   013|    Brian Kim| 45| 75000|\n",
      "|   014|    Emily Lee| 26| 46000|\n",
      "|   015|  Michael Lee| 37| 63000|\n",
      "|   016|  Kelly Zhang| 30| 49000|\n",
      "|   017|  George Wang| 34| 57000|\n",
      "|   018|    Nancy Liu| 29| 50000|\n",
      "|   019|  Steven Chen| 36| 62000|\n",
      "|   020|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa6b3812-f3d4-4ad4-b68d-aeeb62959fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc35136-6829-460d-b61b-6ac017cde1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter emp based on Age > 30\n",
    "# select emp_id, name, age, salary from emp_casted where age > 30\n",
    "\n",
    "emp_final = emp_casted.select(\"emp_id\", \"name\", \"age\", \"salary\").where(\"age > 30\")\n",
    "\n",
    "# Don't worry if you found this little hard. You can directly use SQL schemas in the pyspark there is an example next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dab35d2-f1e5-48ad-8efd-5193084620d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|   003|    Bob Brown| 35| 55000|\n",
      "|   005|    Jack Chan| 40| 60000|\n",
      "|   006|    Jill Wong| 32| 52000|\n",
      "|   007|James Johnson| 42| 70000|\n",
      "|   009|      Tom Tan| 33| 58000|\n",
      "|   011|   David Park| 38| 65000|\n",
      "|   012|   Susan Chen| 31| 54000|\n",
      "|   013|    Brian Kim| 45| 75000|\n",
      "|   015|  Michael Lee| 37| 63000|\n",
      "|   017|  George Wang| 34| 57000|\n",
      "|   019|  Steven Chen| 36| 62000|\n",
      "|   020|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Why do we have to create a Tempview in pyspark to use sql queries?\n",
    "# createOrReplaceTempView: is essential for SQL queries: It registers the DataFrame as a view that SQL context can interact with.\n",
    "# Temporary views make DataFrames queryable by SQL: This step bridges the gap between DataFrame operations and SQL queries in PySpark.\n",
    "emp_casted.createOrReplaceTempView(\"emp_view\")\n",
    "emp_final = spark.sql(\"SELECT emp_id, name, age, salary FROM emp_view WHERE age > 30\")\n",
    "emp_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b15458-15b8-48eb-b4bf-77c6b9f4f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|   003|    Bob Brown| 35| 55000|\n",
      "|   005|    Jack Chan| 40| 60000|\n",
      "|   006|    Jill Wong| 32| 52000|\n",
      "|   007|James Johnson| 42| 70000|\n",
      "|   009|      Tom Tan| 33| 58000|\n",
      "|   011|   David Park| 38| 65000|\n",
      "|   012|   Susan Chen| 31| 54000|\n",
      "|   013|    Brian Kim| 45| 75000|\n",
      "|   015|  Michael Lee| 37| 63000|\n",
      "|   017|  George Wang| 34| 57000|\n",
      "|   019|  Steven Chen| 36| 62000|\n",
      "|   020|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHOW Dataframe (ACTION)\n",
    "\n",
    "emp_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54817dfb-13b7-41a5-9581-a4da1361c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data back as CSV (ACTION)\n",
    "\n",
    "emp_final.write.format(\"csv\").save(\"emp/emp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24192b11-b2d1-49e9-ab29-5f9e69a09928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('emp_id', IntegerType(), True), StructField('name', StringType(), True), StructField('age', IntegerType(), True), StructField('salary', IntegerType(), True)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bonus TIP\n",
    "\n",
    "schema_str = \"emp_id int,name string, age int, salary int\"\n",
    "\n",
    "from pyspark.sql.types import _parse_datatype_string\n",
    "\n",
    "schema_spark = _parse_datatype_string(schema_str)\n",
    "\n",
    "schema_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09106bb-af5a-4c5d-a26c-cc99343b09c8",
   "metadata": {},
   "source": [
    "Use Cases for Defining and Parsing Schema Strings\n",
    "Dynamic Schema Definition:\n",
    "\n",
    "When working with data that has a schema that can change or is defined at runtime, using a schema string allows for flexibility. You can easily modify the schema definition as a string, which is simpler and more readable than manually constructing StructType and StructField objects.\n",
    "Configuration-Driven Schema:\n",
    "\n",
    "In applications where schemas are stored in configuration files (e.g., JSON, YAML), itâ€™s convenient to define schemas as strings. You can read these schema strings from the configuration file and parse them into PySpark schema objects. This approach separates schema definitions from code, making it easier to manage and update schemas without modifying the codebase.\n",
    "Code Readability and Maintainability:\n",
    "\n",
    "Using schema strings improves the readability and maintainability of your code. Defining a schema in a concise string format is more straightforward than the verbose StructType and StructField definitions. This is especially useful for complex schemas with many fields.\n",
    "Interoperability with Other Tools:\n",
    "\n",
    "When integrating PySpark with other tools and platforms that define schemas in a string format (e.g., SQL databases, schema registries), using schema strings in PySpark allows for smoother interoperability. You can directly use these schema definitions in PySpark without conversion overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6af7cd-079b-4def-b56b-c7d2c72414cc",
   "metadata": {},
   "source": [
    "## Spark Hands-on\n",
    "\n",
    "1. Adding Columns\n",
    "2. Using Literals/Static values\n",
    "3. Renaming Columns\n",
    "4. Removing Columns\n",
    "5. Filtering and LIMIT for DataFrame\n",
    "6. Structured Transformations -withColumn, withcolumnRenamed, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9637c0e2-c5d8-4cbf-b9ed-a2179abc8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting Column\n",
    "# select employee_id, name, age, cast(salary as double) as salary from emp\n",
    "from pyspark.sql.functions import col, cast\n",
    "\n",
    "emp_casted = emp.select(\"employee_id\", \"name\", \"age\", col(\"salary\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8840b995-47a3-48a8-aeb0-b135b3f39c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79e93d86-6afe-4ddd-9d84-b20c50c6063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Columns\n",
    "# select employee_id, name, age, salary, (salary * 0.2) as tax from emp_casted\n",
    "\n",
    "emp_taxed = emp_casted.withColumn(\"tax\", col(\"salary\") * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3151e333-45a3-4384-959e-0a1c17f93aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+\n",
      "|employee_id|         name|age| salary|    tax|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "|        001|     John Doe| 30|50000.0|10000.0|\n",
      "|        002|   Jane Smith| 25|45000.0| 9000.0|\n",
      "|        003|    Bob Brown| 35|55000.0|11000.0|\n",
      "|        004|    Alice Lee| 28|48000.0| 9600.0|\n",
      "|        005|    Jack Chan| 40|60000.0|12000.0|\n",
      "|        006|    Jill Wong| 32|52000.0|10400.0|\n",
      "|        007|James Johnson| 42|70000.0|14000.0|\n",
      "|        008|     Kate Kim| 29|51000.0|10200.0|\n",
      "|        009|      Tom Tan| 33|58000.0|11600.0|\n",
      "|        010|     Lisa Lee| 27|47000.0| 9400.0|\n",
      "|        011|   David Park| 38|65000.0|13000.0|\n",
      "|        012|   Susan Chen| 31|54000.0|10800.0|\n",
      "|        013|    Brian Kim| 45|75000.0|15000.0|\n",
      "|        014|    Emily Lee| 26|46000.0| 9200.0|\n",
      "|        015|  Michael Lee| 37|63000.0|12600.0|\n",
      "|        016|  Kelly Zhang| 30|49000.0| 9800.0|\n",
      "|        017|  George Wang| 34|57000.0|11400.0|\n",
      "|        018|    Nancy Liu| 29|50000.0|10000.0|\n",
      "|        019|  Steven Chen| 36|62000.0|12400.0|\n",
      "|        020|    Grace Kim| 32|53000.0|10600.0|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_taxed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dcb3369-4487-438e-9417-4b68df07e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Literals\n",
    "# select employee_id, name, age, salary, tax, 1 as columnOne, 'two' as columnTwo from emp_taxed\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "emp_new_cols = emp_taxed.withColumn(\"columnOne\", lit(1)).withColumn(\"columnTwo\", lit('two'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61f12cd6-2cbf-4c6a-a529-02a58b99533a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|employee_id|         name|age| salary|    tax|columnOne|columnTwo|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|        001|     John Doe| 30|50000.0|10000.0|        1|      two|\n",
      "|        002|   Jane Smith| 25|45000.0| 9000.0|        1|      two|\n",
      "|        003|    Bob Brown| 35|55000.0|11000.0|        1|      two|\n",
      "|        004|    Alice Lee| 28|48000.0| 9600.0|        1|      two|\n",
      "|        005|    Jack Chan| 40|60000.0|12000.0|        1|      two|\n",
      "|        006|    Jill Wong| 32|52000.0|10400.0|        1|      two|\n",
      "|        007|James Johnson| 42|70000.0|14000.0|        1|      two|\n",
      "|        008|     Kate Kim| 29|51000.0|10200.0|        1|      two|\n",
      "|        009|      Tom Tan| 33|58000.0|11600.0|        1|      two|\n",
      "|        010|     Lisa Lee| 27|47000.0| 9400.0|        1|      two|\n",
      "|        011|   David Park| 38|65000.0|13000.0|        1|      two|\n",
      "|        012|   Susan Chen| 31|54000.0|10800.0|        1|      two|\n",
      "|        013|    Brian Kim| 45|75000.0|15000.0|        1|      two|\n",
      "|        014|    Emily Lee| 26|46000.0| 9200.0|        1|      two|\n",
      "|        015|  Michael Lee| 37|63000.0|12600.0|        1|      two|\n",
      "|        016|  Kelly Zhang| 30|49000.0| 9800.0|        1|      two|\n",
      "|        017|  George Wang| 34|57000.0|11400.0|        1|      two|\n",
      "|        018|    Nancy Liu| 29|50000.0|10000.0|        1|      two|\n",
      "|        019|  Steven Chen| 36|62000.0|12400.0|        1|      two|\n",
      "|        020|    Grace Kim| 32|53000.0|10600.0|        1|      two|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_new_cols.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cb33d71-9377-4ecd-b666-6f4d78d8e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Columns\n",
    "# select employee_id as emp_id, name, age, salary, tax, columnOne, columnTwo from emp_new_cols\n",
    "\n",
    "emp_1 = emp_new_cols.withColumnRenamed(\"employee_id\", \"emp_id\")\n",
    "\n",
    "# we can use expr() or selectExpr() as well for renaming columns e.g. selectExpr(\"employee_id as emp_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d02f06d-0f39-4dc3-97c8-13f56d6b32ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "|emp_id|         name|age| salary|    tax|columnOne|columnTwo|\n",
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "|   001|     John Doe| 30|50000.0|10000.0|        1|      two|\n",
      "|   002|   Jane Smith| 25|45000.0| 9000.0|        1|      two|\n",
      "|   003|    Bob Brown| 35|55000.0|11000.0|        1|      two|\n",
      "|   004|    Alice Lee| 28|48000.0| 9600.0|        1|      two|\n",
      "|   005|    Jack Chan| 40|60000.0|12000.0|        1|      two|\n",
      "|   006|    Jill Wong| 32|52000.0|10400.0|        1|      two|\n",
      "|   007|James Johnson| 42|70000.0|14000.0|        1|      two|\n",
      "|   008|     Kate Kim| 29|51000.0|10200.0|        1|      two|\n",
      "|   009|      Tom Tan| 33|58000.0|11600.0|        1|      two|\n",
      "|   010|     Lisa Lee| 27|47000.0| 9400.0|        1|      two|\n",
      "|   011|   David Park| 38|65000.0|13000.0|        1|      two|\n",
      "|   012|   Susan Chen| 31|54000.0|10800.0|        1|      two|\n",
      "|   013|    Brian Kim| 45|75000.0|15000.0|        1|      two|\n",
      "|   014|    Emily Lee| 26|46000.0| 9200.0|        1|      two|\n",
      "|   015|  Michael Lee| 37|63000.0|12600.0|        1|      two|\n",
      "|   016|  Kelly Zhang| 30|49000.0| 9800.0|        1|      two|\n",
      "|   017|  George Wang| 34|57000.0|11400.0|        1|      two|\n",
      "|   018|    Nancy Liu| 29|50000.0|10000.0|        1|      two|\n",
      "|   019|  Steven Chen| 36|62000.0|12400.0|        1|      two|\n",
      "|   020|    Grace Kim| 32|53000.0|10600.0|        1|      two|\n",
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de529bfb-dc59-4d66-8afb-5143b7d12aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names with Spaces\n",
    "# select employee_id as emp_id, name, age, salary, tax, columnOne, columnTwo as `Column Two` from emp_new_cols\n",
    "\n",
    "emp_2 = emp_new_cols.withColumnRenamed(\"columnTwo\", \"Column Two\")\n",
    "\n",
    "# As you know in Programming we always use \"_\", \"Cameling method(DataTypes)\" for names so always follow this rule because in the downstrem if you didn't use this, it will cause\n",
    "# an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ebdfaab-bd2d-4154-a409-b151ce300978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+---------+----------+\n",
      "|employee_id|         name|age| salary|    tax|columnOne|Column Two|\n",
      "+-----------+-------------+---+-------+-------+---------+----------+\n",
      "|        001|     John Doe| 30|50000.0|10000.0|        1|       two|\n",
      "|        002|   Jane Smith| 25|45000.0| 9000.0|        1|       two|\n",
      "|        003|    Bob Brown| 35|55000.0|11000.0|        1|       two|\n",
      "|        004|    Alice Lee| 28|48000.0| 9600.0|        1|       two|\n",
      "|        005|    Jack Chan| 40|60000.0|12000.0|        1|       two|\n",
      "|        006|    Jill Wong| 32|52000.0|10400.0|        1|       two|\n",
      "|        007|James Johnson| 42|70000.0|14000.0|        1|       two|\n",
      "|        008|     Kate Kim| 29|51000.0|10200.0|        1|       two|\n",
      "|        009|      Tom Tan| 33|58000.0|11600.0|        1|       two|\n",
      "|        010|     Lisa Lee| 27|47000.0| 9400.0|        1|       two|\n",
      "|        011|   David Park| 38|65000.0|13000.0|        1|       two|\n",
      "|        012|   Susan Chen| 31|54000.0|10800.0|        1|       two|\n",
      "|        013|    Brian Kim| 45|75000.0|15000.0|        1|       two|\n",
      "|        014|    Emily Lee| 26|46000.0| 9200.0|        1|       two|\n",
      "|        015|  Michael Lee| 37|63000.0|12600.0|        1|       two|\n",
      "|        016|  Kelly Zhang| 30|49000.0| 9800.0|        1|       two|\n",
      "|        017|  George Wang| 34|57000.0|11400.0|        1|       two|\n",
      "|        018|    Nancy Liu| 29|50000.0|10000.0|        1|       two|\n",
      "|        019|  Steven Chen| 36|62000.0|12400.0|        1|       two|\n",
      "|        020|    Grace Kim| 32|53000.0|10600.0|        1|       two|\n",
      "+-----------+-------------+---+-------+-------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e06e4871-f9a6-4f4a-93f0-b07b8bd63c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Column\n",
    "\n",
    "emp_dropped = emp_new_cols.drop(\"columnTwo\", \"columnOne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3941d492-120b-40ec-bff1-7fe93ea748a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+\n",
      "|employee_id|         name|age| salary|    tax|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "|        001|     John Doe| 30|50000.0|10000.0|\n",
      "|        002|   Jane Smith| 25|45000.0| 9000.0|\n",
      "|        003|    Bob Brown| 35|55000.0|11000.0|\n",
      "|        004|    Alice Lee| 28|48000.0| 9600.0|\n",
      "|        005|    Jack Chan| 40|60000.0|12000.0|\n",
      "|        006|    Jill Wong| 32|52000.0|10400.0|\n",
      "|        007|James Johnson| 42|70000.0|14000.0|\n",
      "|        008|     Kate Kim| 29|51000.0|10200.0|\n",
      "|        009|      Tom Tan| 33|58000.0|11600.0|\n",
      "|        010|     Lisa Lee| 27|47000.0| 9400.0|\n",
      "|        011|   David Park| 38|65000.0|13000.0|\n",
      "|        012|   Susan Chen| 31|54000.0|10800.0|\n",
      "|        013|    Brian Kim| 45|75000.0|15000.0|\n",
      "|        014|    Emily Lee| 26|46000.0| 9200.0|\n",
      "|        015|  Michael Lee| 37|63000.0|12600.0|\n",
      "|        016|  Kelly Zhang| 30|49000.0| 9800.0|\n",
      "|        017|  George Wang| 34|57000.0|11400.0|\n",
      "|        018|    Nancy Liu| 29|50000.0|10000.0|\n",
      "|        019|  Steven Chen| 36|62000.0|12400.0|\n",
      "|        020|    Grace Kim| 32|53000.0|10600.0|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_dropped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eb55b7c-ede2-4e21-9432-75ba5e408113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data \n",
    "# select employee_id as emp_id, name, age, salary, tax, columnOne from emp_col_dropped where tax > 1000\n",
    "\n",
    "emp_filtered = emp_dropped.where(\"tax > 10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f8376cf-1509-4be7-b56f-4cfa17421b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+\n",
      "|employee_id|         name|age| salary|    tax|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "|        003|    Bob Brown| 35|55000.0|11000.0|\n",
      "|        005|    Jack Chan| 40|60000.0|12000.0|\n",
      "|        006|    Jill Wong| 32|52000.0|10400.0|\n",
      "|        007|James Johnson| 42|70000.0|14000.0|\n",
      "|        008|     Kate Kim| 29|51000.0|10200.0|\n",
      "|        009|      Tom Tan| 33|58000.0|11600.0|\n",
      "|        011|   David Park| 38|65000.0|13000.0|\n",
      "|        012|   Susan Chen| 31|54000.0|10800.0|\n",
      "|        013|    Brian Kim| 45|75000.0|15000.0|\n",
      "|        015|  Michael Lee| 37|63000.0|12600.0|\n",
      "|        017|  George Wang| 34|57000.0|11400.0|\n",
      "|        019|  Steven Chen| 36|62000.0|12400.0|\n",
      "|        020|    Grace Kim| 32|53000.0|10600.0|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "254d1e27-a9a3-4172-8aa4-30c0f7af2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMIT data\n",
    "# select employee_id as emp_id, name, age, salary, tax, columnOne from emp_filtered limit 5\n",
    "\n",
    "emp_limit = emp_filtered.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "405d183e-48dc-41fa-a3a0-6b7e4a33afc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---+-------+-------+\n",
      "|employee_id|     name|age| salary|    tax|\n",
      "+-----------+---------+---+-------+-------+\n",
      "|        003|Bob Brown| 35|55000.0|11000.0|\n",
      "|        005|Jack Chan| 40|60000.0|12000.0|\n",
      "+-----------+---------+---+-------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show data\n",
    "\n",
    "emp_limit.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "832976c6-ac33-43cd-86ed-46d8d713f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus TIP\n",
    "# Add multiple columns\n",
    "\n",
    "columns = {\n",
    "    \"tax\" : col(\"salary\") * 0.2 ,\n",
    "    \"oneNumber\" : lit(1), \n",
    "    \"columnTwo\" : lit(\"two\")\n",
    "}\n",
    "\n",
    "emp_final = emp.withColumns(columns)\n",
    "\n",
    "# Take a note we are using withcolumns() this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0991a6c-e84f-44ca-a9f7-9da5b31d3309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+-------+---------+---------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|    tax|oneNumber|columnTwo|\n",
      "+-----------+-------------+-------------+---+------+------+----------+-------+---------+---------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|10000.0|        1|      two|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15| 9000.0|        1|      two|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|11000.0|        1|      two|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30| 9600.0|        1|      two|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|12000.0|        1|      two|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|10400.0|        1|      two|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|14000.0|        1|      two|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|10200.0|        1|      two|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|11600.0|        1|      two|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01| 9400.0|        1|      two|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|13000.0|        1|      two|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|10800.0|        1|      two|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|15000.0|        1|      two|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01| 9200.0|        1|      two|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|12600.0|        1|      two|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01| 9800.0|        1|      two|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|11400.0|        1|      two|\n",
      "|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|10000.0|        1|      two|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|12400.0|        1|      two|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|10600.0|        1|      two|\n",
      "+-----------+-------------+-------------+---+------+------+----------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604c3b0-b860-470b-bf1a-ea0fda5f9ad1",
   "metadata": {},
   "source": [
    "## Working with Strings, Dates and Null\n",
    "\n",
    "1. Writing with String Data\n",
    "   1. Case When, Regex_replace etc\n",
    "2. Working with Dates\n",
    "   1. to_date, current_date, current_timestamp\n",
    "3. Working with NULL values\n",
    "   1. nvl, na.drop, na.fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "478a1942-cc3c-405e-91ec-7085b1f24243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case When\n",
    "# select employee_id, name, age, salary, gender,\n",
    "# case when gender = 'Male' then 'M' when gender = 'Female' then 'F' else null end as new_gender, hire_date from emp\n",
    "from pyspark.sql.functions import when, col, expr\n",
    "\n",
    "emp_gender_fixed = emp.withColumn(\"new_gender\", when(col(\"gender\") == 'Male', 'M')\n",
    "                                 .when(col(\"gender\") == 'Female', 'F')\n",
    "                                 .otherwise(None)\n",
    "                                 )\n",
    "                            \n",
    "emp_gender_fixed_1 = emp.withColumn(\"new_gender\", expr(\"case when gender = 'Male' then 'M' when gender = 'Female' then 'F' else null end\"))\n",
    "\n",
    "#emp.createOrReplaceTempView(\"emp\")\n",
    "\n",
    "#result = spark.sql(\"\"\"\n",
    "#SELECT \n",
    "#    employee_id, \n",
    "#   name, \n",
    "#    age, \n",
    "#     salary, \n",
    "#     gender,\n",
    "#     CASE \n",
    "#         WHEN gender = 'Male' THEN 'M' \n",
    "#         WHEN gender = 'Female' THEN 'F' \n",
    "#         ELSE NULL \n",
    "#     END AS new_gender,\n",
    "#     hire_date \n",
    "# FROM emp\n",
    "# \"\"\")\n",
    "# result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56bfea44-1be2-43a9-b4b6-cb4846464cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|new_gender|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|         M|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|         F|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|         M|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|         F|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|         M|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|         F|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|         M|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|         F|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|         M|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|         F|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|         M|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|         F|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|         M|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|         F|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|         M|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|         F|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|         M|\n",
      "|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|         F|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|         M|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|         F|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_gender_fixed_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af691da3-8b7e-4924-bdd1-18be60d8a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in Strings\n",
    "# select employee_id, name, replace(name, 'J', 'Z') as new_name, age, salary, gender, new_gender, hire_date from emp_gender_fixed\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "emp_name_fixed = emp_gender_fixed.withColumn(\"new_name\", regexp_replace(col(\"name\"), \"J\", \"Z\"))\n",
    "\n",
    "# SELECT \n",
    "#     employee_id, \n",
    "#     name, \n",
    "#     REGEXP_REPLACE(name, 'J', 'Z') AS new_name, \n",
    "#     age, \n",
    "#     salary, \n",
    "#     gender, \n",
    "#     new_gender, \n",
    "#     hire_date \n",
    "# FROM emp_gender_fixed;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2ccc9ea-fb67-437f-9f74-e30a7cfd2126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|new_gender|     new_name|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|         M|     Zohn Doe|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|         F|   Zane Smith|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|         M|    Bob Brown|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|         F|    Alice Lee|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|         M|    Zack Chan|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|         F|    Zill Wong|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|         M|Zames Zohnson|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|         F|     Kate Kim|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|         M|      Tom Tan|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|         F|     Lisa Lee|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|         M|   David Park|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|         F|   Susan Chen|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|         M|    Brian Kim|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|         F|    Emily Lee|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|         M|  Michael Lee|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|         F|  Kelly Zhang|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|         M|  George Wang|\n",
      "|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|         F|    Nancy Liu|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|         M|  Steven Chen|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|         F|    Grace Kim|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_name_fixed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cda49b4-50b7-4558-b8b5-d0a80b39b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date\n",
    "# select *,  to_date(hire_date, 'YYYY-MM-DD') as hire_date from emp_name_fixed\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "emp_date_fix = emp_name_fixed.withColumn(\"hire_date\", to_date(col(\"hire_date\"), 'yyyy-MM-dd'))\n",
    "\n",
    "# SELECT \n",
    "#     *, \n",
    "#     TO_DATE(hire_date, 'yyyy-MM-dd') AS hire_date \n",
    "# FROM emp_name_fixed;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14aea2b0-4b83-4aee-ab7d-0ee5df728213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- department_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      " |-- new_gender: string (nullable = true)\n",
      " |-- new_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_date_fix.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b358b4fc-bdcd-4d3e-a711-aa12ab3c2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Date Columns\n",
    "# Add current_date, current_timestamp, extract year from hire_date\n",
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "\n",
    "emp_dated = emp_date_fix.withColumn(\"date_now\", current_date()).withColumn(\"timestamp_now\", current_timestamp())\n",
    "\n",
    "# SELECT \n",
    "#     *, \n",
    "#     CURRENT_DATE() AS date_now, \n",
    "#     CURRENT_TIMESTAMP() AS timestamp_now, \n",
    "#     YEAR(hire_date) AS hire_year \n",
    "# FROM emp_date_fix;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93d98708-803b-43ea-a53c-3823cd2750df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+-------------------------+\n",
      "|employee_id|department_id|name         |age|gender|salary|hire_date |new_gender|new_name     |date_now  |timestamp_now            |\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+-------------------------+\n",
      "|001        |101          |John Doe     |30 |Male  |50000 |2015-01-01|M         |Zohn Doe     |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|002        |101          |Jane Smith   |25 |Female|45000 |2016-02-15|F         |Zane Smith   |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|003        |102          |Bob Brown    |35 |Male  |55000 |2014-05-01|M         |Bob Brown    |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|004        |102          |Alice Lee    |28 |Female|48000 |2017-09-30|F         |Alice Lee    |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|005        |103          |Jack Chan    |40 |Male  |60000 |2013-04-01|M         |Zack Chan    |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|006        |103          |Jill Wong    |32 |Female|52000 |2018-07-01|F         |Zill Wong    |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|007        |101          |James Johnson|42 |Male  |70000 |2012-03-15|M         |Zames Zohnson|2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|008        |102          |Kate Kim     |29 |Female|51000 |2019-10-01|F         |Kate Kim     |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|009        |103          |Tom Tan      |33 |Male  |58000 |2016-06-01|M         |Tom Tan      |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|010        |104          |Lisa Lee     |27 |Female|47000 |2018-08-01|F         |Lisa Lee     |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|011        |104          |David Park   |38 |Male  |65000 |2015-11-01|M         |David Park   |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|012        |105          |Susan Chen   |31 |Female|54000 |2017-02-15|F         |Susan Chen   |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|013        |106          |Brian Kim    |45 |Male  |75000 |2011-07-01|M         |Brian Kim    |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|014        |107          |Emily Lee    |26 |Female|46000 |2019-01-01|F         |Emily Lee    |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|015        |106          |Michael Lee  |37 |Male  |63000 |2014-09-30|M         |Michael Lee  |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|016        |107          |Kelly Zhang  |30 |Female|49000 |2018-04-01|F         |Kelly Zhang  |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|017        |105          |George Wang  |34 |Male  |57000 |2016-03-15|M         |George Wang  |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|018        |104          |Nancy Liu    |29 |Female|50000 |2017-06-01|F         |Nancy Liu    |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|019        |103          |Steven Chen  |36 |Male  |62000 |2015-08-01|M         |Steven Chen  |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "|020        |102          |Grace Kim    |32 |Female|53000 |2018-11-01|F         |Grace Kim    |2024-07-23|2024-07-23 18:28:12.60719|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_dated.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3dc8fdb2-f8f4-4bb4-944b-bb3acb0ffa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null gender records\n",
    "emp_1 = emp_dated.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7acc22d-84c5-4721-8a5a-352d707cabca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|new_gender|     new_name|  date_now|       timestamp_now|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|         M|     Zohn Doe|2024-07-23|2024-07-23 18:28:...|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|         F|   Zane Smith|2024-07-23|2024-07-23 18:28:...|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|         M|    Bob Brown|2024-07-23|2024-07-23 18:28:...|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|         F|    Alice Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|         M|    Zack Chan|2024-07-23|2024-07-23 18:28:...|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|         F|    Zill Wong|2024-07-23|2024-07-23 18:28:...|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|         M|Zames Zohnson|2024-07-23|2024-07-23 18:28:...|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|         F|     Kate Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|         M|      Tom Tan|2024-07-23|2024-07-23 18:28:...|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|         F|     Lisa Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|         M|   David Park|2024-07-23|2024-07-23 18:28:...|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|         F|   Susan Chen|2024-07-23|2024-07-23 18:28:...|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|         M|    Brian Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|         F|    Emily Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|         M|  Michael Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|         F|  Kelly Zhang|2024-07-23|2024-07-23 18:28:...|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|         M|  George Wang|2024-07-23|2024-07-23 18:28:...|\n",
      "|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|         F|    Nancy Liu|2024-07-23|2024-07-23 18:28:...|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|         M|  Steven Chen|2024-07-23|2024-07-23 18:28:...|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|         F|    Grace Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c0741e5-f031-4f0c-884a-e668cbec24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Null values\n",
    "# select *, nvl('new_gender', 'O') as new_gender from emp_dated\n",
    "from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "emp_null_df = emp_dated.withColumn(\"new_gender\", coalesce(col(\"new_gender\"), lit(\"O\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4074d648-e7f2-4b83-ba0f-98a409e1c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|new_gender|     new_name|  date_now|       timestamp_now|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|         M|     Zohn Doe|2024-07-23|2024-07-23 18:28:...|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|         F|   Zane Smith|2024-07-23|2024-07-23 18:28:...|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|         M|    Bob Brown|2024-07-23|2024-07-23 18:28:...|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|         F|    Alice Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|         M|    Zack Chan|2024-07-23|2024-07-23 18:28:...|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|         F|    Zill Wong|2024-07-23|2024-07-23 18:28:...|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|         M|Zames Zohnson|2024-07-23|2024-07-23 18:28:...|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|         F|     Kate Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|         M|      Tom Tan|2024-07-23|2024-07-23 18:28:...|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|         F|     Lisa Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|         M|   David Park|2024-07-23|2024-07-23 18:28:...|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|         F|   Susan Chen|2024-07-23|2024-07-23 18:28:...|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|         M|    Brian Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|         F|    Emily Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|         M|  Michael Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|         F|  Kelly Zhang|2024-07-23|2024-07-23 18:28:...|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|         M|  George Wang|2024-07-23|2024-07-23 18:28:...|\n",
      "|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|         F|    Nancy Liu|2024-07-23|2024-07-23 18:28:...|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|         M|  Steven Chen|2024-07-23|2024-07-23 18:28:...|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|         F|    Grace Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "+-----------+-------------+-------------+---+------+------+----------+----------+-------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_null_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c65b652e-2054-4f6f-9b7d-98d3b9ef1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop old columns and Fix new column names\n",
    "emp_final = emp_null_df.drop(\"name\", \"gender\").withColumnRenamed(\"new_name\", \"name\").withColumnRenamed(\"new_gender\", \"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e740e529-35da-4289-842e-1be037f13c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+\n",
      "|employee_id|department_id|age|salary| hire_date|gender|         name|  date_now|       timestamp_now|\n",
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+\n",
      "|        001|          101| 30| 50000|2015-01-01|     M|     Zohn Doe|2024-07-23|2024-07-23 18:28:...|\n",
      "|        002|          101| 25| 45000|2016-02-15|     F|   Zane Smith|2024-07-23|2024-07-23 18:28:...|\n",
      "|        003|          102| 35| 55000|2014-05-01|     M|    Bob Brown|2024-07-23|2024-07-23 18:28:...|\n",
      "|        004|          102| 28| 48000|2017-09-30|     F|    Alice Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        005|          103| 40| 60000|2013-04-01|     M|    Zack Chan|2024-07-23|2024-07-23 18:28:...|\n",
      "|        006|          103| 32| 52000|2018-07-01|     F|    Zill Wong|2024-07-23|2024-07-23 18:28:...|\n",
      "|        007|          101| 42| 70000|2012-03-15|     M|Zames Zohnson|2024-07-23|2024-07-23 18:28:...|\n",
      "|        008|          102| 29| 51000|2019-10-01|     F|     Kate Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "|        009|          103| 33| 58000|2016-06-01|     M|      Tom Tan|2024-07-23|2024-07-23 18:28:...|\n",
      "|        010|          104| 27| 47000|2018-08-01|     F|     Lisa Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        011|          104| 38| 65000|2015-11-01|     M|   David Park|2024-07-23|2024-07-23 18:28:...|\n",
      "|        012|          105| 31| 54000|2017-02-15|     F|   Susan Chen|2024-07-23|2024-07-23 18:28:...|\n",
      "|        013|          106| 45| 75000|2011-07-01|     M|    Brian Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "|        014|          107| 26| 46000|2019-01-01|     F|    Emily Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        015|          106| 37| 63000|2014-09-30|     M|  Michael Lee|2024-07-23|2024-07-23 18:28:...|\n",
      "|        016|          107| 30| 49000|2018-04-01|     F|  Kelly Zhang|2024-07-23|2024-07-23 18:28:...|\n",
      "|        017|          105| 34| 57000|2016-03-15|     M|  George Wang|2024-07-23|2024-07-23 18:28:...|\n",
      "|        018|          104| 29| 50000|2017-06-01|     F|    Nancy Liu|2024-07-23|2024-07-23 18:28:...|\n",
      "|        019|          103| 36| 62000|2015-08-01|     M|  Steven Chen|2024-07-23|2024-07-23 18:28:...|\n",
      "|        020|          102| 32| 53000|2018-11-01|     F|    Grace Kim|2024-07-23|2024-07-23 18:28:...|\n",
      "+-----------+-------------+---+------+----------+------+-------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8014edf-36cb-48f4-a29e-36e5cc2c2381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e07938-2fb9-4a14-b6a6-6c2cfb74ab0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3228a4-f621-4b6b-adac-62ba025dfaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01634de-9f3d-41a4-836e-81244edfddfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
